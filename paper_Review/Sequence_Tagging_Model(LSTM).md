# 摘要
- 这篇文章介绍了几种基于LSTM网络的序列标注模型，包括LSTM、BI-LSTM、CRF、LSTM-CRF和BI-LSTM-CRF。
- 作者在三个NLP标注任务（POS、chunking和NER）上对这些模型进行了系统的比较，并提出了首次将BI-LSTM-CRF模型应用于NLP基准序列标注数据集的工作。
- 实验结果表明，BI-LSTM-CRF模型可以在POS、chunking和NER数据集上达到最优或接近最优的准确率。
- 此外，该模型也比较稳健，对词嵌入的依赖性较低。

# LSTM是什么
- LSTM是Long Short-Term Memory的缩写，是一种人工神经网络，用于人工智能和深度学习领域。
与标准的前馈神经网络不同，LSTM具有反馈连接。
这样的循环神经网络（RNN）不仅可以处理单个数据点（如图像），还可以处理整个数据序列（如语音或视频）。
这种特性使得LSTM网络适合处理和预测数据。
例如，LSTM可以应用于诸如未分割的连续手写识别、语音识别、机器翻译、语音活动检测、机器人控制、视频游戏和医疗等任务。

- LSTM的名称是指标准RNN具有“长期记忆”和“短期记忆”的类比。
网络中的连接权重和偏置在每次训练时改变一次，类似于生理上的突触强度变化存储长期记忆；网络中的激活模式在每个时间步改变一次，类似于大脑中电火花模式的瞬时变化存储短期记忆。
LSTM架构旨在为RNN提供一种可以持续数千个时间步的短期记忆，因此称为“长短期记忆"。

- 一个常见的LSTM单元由一个单元、一个输入门、一个输出门和一个遗忘门组成。单元可以在任意时间间隔内记住值，三个门可以调节信息流入和流出单元的情况。
遗忘门决定从前一个状态丢弃哪些信息，通过给前一个状态和当前输入分配一个0到1之间的值来实现。
一个（四舍五入的）值为1表示保留信息，一个值为0表示丢弃信息。输入门决定将哪些新信息存储在当前状态中，使用与遗忘门相同的系统。
输出门控制当前状态中哪些信息输出，通过给信息分配一个0到1之间的值来实现，考虑前一个和当前状态。

